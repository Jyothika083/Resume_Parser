{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxu83+S9R0asq4ceBNk6pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyothika083/Resume_Parser/blob/main/Mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pAIe84575p4",
        "outputId": "375f0c9d-fc60-46e5-b2eb-4aa09c3bb32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (3.7.4)\n",
            "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.4.8)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers)\n",
            "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (2023.12.25)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37.0,>=3.4.0->spacy-transformers)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.4.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.0)\n",
            "Installing collected packages: spacy-alignments, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, spacy-transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.1\n",
            "    Uninstalling transformers-4.40.1:\n",
            "      Successfully uninstalled transformers-4.40.1\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 spacy-alignments-0.9.1 spacy-transformers-1.3.5 tokenizers-0.15.2 transformers-4.36.2\n"
          ]
        }
      ],
      "source": [
        "pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "X8rNAoyK7-ZG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU8EWh5U8CdS",
        "outputId": "1f6ce2f3-0d44-450b-84e8-d8100c2ef605"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  8 11:24:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OmzjetC8Jf7",
        "outputId": "c5d117f5-f418-4844-e453-19945a817bd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV-Parsing-using-Spacy-3'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 82 (delta 14), reused 74 (delta 14), pack-reused 6\u001b[K\n",
            "Receiving objects: 100% (82/82), 5.62 MiB | 22.29 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data = json.load(open('/content/CV-Parsing-using-Spacy-3/data/training/train_data.json', 'r'))"
      ],
      "metadata": {
        "id": "wUHEcxXd8KN6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsHrmKU8MkQ",
        "outputId": "77a89143-bb9d-409f-cc1b-0ce525a407e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/CV-Parsing-using-Spacy-3/data/training/base_config.cfg /content/CV-Parsing-using-Spacy-3/data/training/config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzDqMlM78OEk",
        "outputId": "9a7f0c0a-c769-4c97-931d-b8e4eb280cbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls7yuRMd8lmR",
        "outputId": "d1e3af5c-40a0-42a4-db9f-adbe8841bbf9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [[1749, 1755, 'Companies worked at'],\n",
              "   [1696, 1702, 'Companies worked at'],\n",
              "   [1417, 1423, 'Companies worked at'],\n",
              "   [1356, 1793, 'Skills'],\n",
              "   [1209, 1215, 'Companies worked at'],\n",
              "   [1136, 1247, 'Skills'],\n",
              "   [928, 932, 'Graduation Year'],\n",
              "   [858, 889, 'College Name'],\n",
              "   [821, 856, 'Degree'],\n",
              "   [787, 791, 'Graduation Year'],\n",
              "   [744, 750, 'Companies worked at'],\n",
              "   [722, 742, 'Designation'],\n",
              "   [658, 664, 'Companies worked at'],\n",
              "   [640, 656, 'Designation'],\n",
              "   [574, 580, 'Companies worked at'],\n",
              "   [555, 572, 'Designation'],\n",
              "   [470, 493, 'Companies worked at'],\n",
              "   [444, 468, 'Designation'],\n",
              "   [308, 314, 'Companies worked at'],\n",
              "   [234, 240, 'Companies worked at'],\n",
              "   [175, 198, 'Companies worked at'],\n",
              "   [93, 136, 'Email Address'],\n",
              "   [39, 48, 'Location'],\n",
              "   [13, 37, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file,data):\n",
        "  nlp = spacy.blank('en')\n",
        "  db = DocBin()\n",
        "\n",
        "  for text, annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "\n",
        "    ents = []\n",
        "    entitiy_indices = []\n",
        "\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start, end):\n",
        "        if idx in entitiy_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity ==True:\n",
        "        continue\n",
        "\n",
        "      entitiy_indices = entitiy_indices + list(range(start, end))\n",
        "\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if span is None:\n",
        "        err_data = str([start, end]) +\"  \"+ str(text)+ \"\\n\"\n",
        "        file.write(err_data)\n",
        "      else:\n",
        "        ents.append(span)\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "  return db\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DD1mkcv88QGo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_data, test_size = 0.3)"
      ],
      "metadata": {
        "id": "0TUVLEZT83JG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('error.txt','w', encoding='utf-8')\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('train_data.spacy')\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A4QFEUc86UU",
        "outputId": "151f0775-efd5-4a50-ecb6-6b8e933a7b90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "100%|██████████| 140/140 [00:01<00:00, 88.79it/s] \n",
            "100%|██████████| 60/60 [00:01<00:00, 59.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!python -m spacy train /content/CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRIeRohx88iG",
        "outputId": "0142579a-4cd6-43b4-ba12-ec0b358cc6d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 127kB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 2.77MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 14.8MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 50.8MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 55.2MB/s]\n",
            "model.safetensors: 100% 499M/499M [00:03<00:00, 154MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        2923.28   1593.73    0.08    0.04    1.52    0.00\n",
            "  4     200      325844.55  69170.29   29.38   35.29   25.16    0.29\n",
            "  8     400       42414.94  23170.09   56.50   55.37   57.69    0.57\n",
            " 12     600        6532.53  19752.96   55.90   50.46   62.64    0.56\n",
            " 16     800        3138.73  17700.40   57.35   58.72   56.04    0.57\n",
            " 20    1000        7440.94  16447.15   54.79   57.93   51.97    0.55\n",
            " 24    1200        1654.40  15358.90   56.40   56.51   56.29    0.56\n",
            " 28    1400         713.02  14284.04   55.61   52.42   59.21    0.56\n",
            " 32    1600         460.78  13726.87   58.62   59.58   57.69    0.59\n",
            " 36    1800         446.00  13213.22   57.13   52.50   62.64    0.57\n",
            " 40    2000        2876.10  12845.23   57.62   52.63   63.66    0.58\n",
            " 44    2200         632.41  12258.20   58.80   57.21   60.48    0.59\n",
            " 48    2400         494.07  11552.63   57.30   54.96   59.85    0.57\n",
            " 52    2600         344.61  10864.95   58.36   56.71   60.10    0.58\n",
            " 56    2800         467.68  10015.41   58.81   60.68   57.05    0.59\n",
            " 60    3000         396.93   9129.56   60.17   60.36   59.97    0.60\n",
            " 64    3200         273.28   8082.51   57.74   54.31   61.63    0.58\n",
            " 68    3400         199.31   6908.63   60.31   58.14   62.64    0.60\n",
            " 72    3600        4140.54   5804.21   57.24   58.77   55.78    0.57\n",
            " 76    3800        4687.43   4711.67   58.26   56.99   59.59    0.58\n",
            " 80    4000         632.07   3492.52   58.00   57.32   58.70    0.58\n",
            " 84    4200         454.66   2520.29   59.96   61.69   58.32    0.60\n",
            " 88    4400         188.94   1693.40   59.87   60.81   58.96    0.60\n",
            " 92    4600      153186.99   1813.23   59.52   60.50   58.58    0.60\n",
            " 96    4800         264.27    757.06   59.06   58.91   59.21    0.59\n",
            "100    5000         615.41    499.99   58.01   57.83   58.20    0.58\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('/content/output/model-best')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_VGP3wjQ9U6",
        "outputId": "e6333141-4798-444b-a71e-03d19e126cab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pyldr0kRnlD",
        "outputId": "91f70d9d-0481-4467-a760-1b86293da927"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.2-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.1 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.2 PyMuPDFb-1.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz"
      ],
      "metadata": {
        "id": "yxYozJ5ARpWn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = '/content/CV-Parsing-using-Spacy-3/data/test/Alice Clark CV.pdf'\n",
        "doc = fitz.open(fname)"
      ],
      "metadata": {
        "id": "5uLZFsFDRrjW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \"\n",
        "for page in doc:\n",
        "  text = text + str(page.get_text())"
      ],
      "metadata": {
        "id": "LDjWSZ9_RuYA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.strip()"
      ],
      "metadata": {
        "id": "sBlfERzFRwpa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text.split())"
      ],
      "metadata": {
        "id": "7Ud92y8xRya4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc =nlp(text)\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"--------->\" , ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVMMaHz-R0iQ",
        "outputId": "7a274657-c97d-4128-bc6d-d6a9d3b02b4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice Clark ---------> Name\n",
            "AI / Machine Learning Delhi ---------> Designation\n",
            "20+ years ---------> Years of Experience\n",
            "Software Engineer ---------> Designation\n",
            "Microsoft ---------> Companies worked at\n",
            "Indian Institute of Technology ---------> College Name\n",
            "2001 ---------> Graduation Year\n",
            "Machine Learning, Natural Language Processing, and Big Data Handling ADDITIONAL INFORMATION Professional Skills • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills with ability to interact with individuals at all the levels • Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments • Positive attitude towards superiors &amp; peers • Supervised junior developers throughout project lifecycle and provided technical assistance ---------> Skills\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Domain prediction"
      ],
      "metadata": {
        "id": "dxux6J5Oa653"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "hG87i--TatfZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akovzvarbHQC",
        "outputId": "bb96578c-9e75-4f85-f7af-5f5be0f868c4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/UpdatedResumeDataSet.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1AXzS5tDbH3X",
        "outputId": "f9603bf1-0da0-4149-e65a-7ad74f1e3ea9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Category                                             Resume\n",
              "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
              "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
              "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
              "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
              "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd7fdab8-6926-460d-a3b4-20dd4e396760\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd7fdab8-6926-460d-a3b4-20dd4e396760')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd7fdab8-6926-460d-a3b4-20dd4e396760 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd7fdab8-6926-460d-a3b4-20dd4e396760');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5105fc6c-f381-4fdc-a7fd-180fdc687954\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5105fc6c-f381-4fdc-a7fd-180fdc687954')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5105fc6c-f381-4fdc-a7fd-180fdc687954 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 962,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Civil Engineer\",\n          \"DevOps Engineer\",\n          \"Data Science\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resume\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"KEY COMPETENCIES \\u00e2\\u009c\\u00b6Multi - Operations Management\\u00e2\\u009c\\u00b6People Management \\u00e2\\u009c\\u00b6Customer Services - Emails \\u00e2\\u009c\\u00b6 MIS \\u00e2\\u009c\\u00b6Vendor & Client Services Management\\u00e2\\u009c\\u00b6Cross Functional Coordination\\u00e2\\u009c\\u00b6Banking & Financial Services\\u00e2\\u009c\\u00b6 Transaction Monitoring * ATM Operations \\u00e2\\u009c\\u00b6 & Prepaid Card Operations (Pre-Issuance & Post-Issuance) \\u00e2\\u009c\\u00b6 POS Operations * JOB PROFILE & SKILLS: \\u00e2\\u0080\\u00a2 An effective communicator with excellent relationship building & interpersonal skills. Strong analytical, problem solving & organizational abilities. \\u00e2\\u0080\\u00a2 Extensive experience in managing operations with demonstrated leadership qualities & organisational skills during the tenure. \\u00e2\\u0080\\u00a2 Managing customer centric operations & ensuring customer satisfaction by achieving service quality norms. \\u00e2\\u0080\\u00a2 Analyzing of all operational problems, customer complaints and take preventive and corrective actions to resolve the same. \\u00e2\\u0080\\u00a2 Receive and respond to Key customer inquiries in an effective manner and provide relevant and timely information. \\u00e2\\u0080\\u00a2 Deft in steering banking back-end operations, analyzing risks and managing delinquencies with dexterity across applying techniques for maximizing recoveries and minimizing credit losses. \\u00e2\\u0080\\u00a2 Analyzed & identified training needs of the team members and developing, organizing and conducting training programs and manage bottom quartile team to improve their performance. \\u00e2\\u0080\\u00a2 Preparing and maintaining daily MIS reports to evaluate the performance and efficiency of the process relate to various verticals. \\u00e2\\u0080\\u00a2 Measuring the performance of the processes in terms of efficiency and effectiveness matrix and ensuring adherence to SLA. \\u00e2\\u0080\\u00a2 Major Activities Define processes for Field Services were monitored and necessary checks were executed and controlled. Also measured Vendor SLA by analyzing the TAT of vendors & the Client SLA provided to us. \\u00e2\\u0080\\u00a2 As per company procedures, handling & ensuring vendor's payment issues to be sorted out &payments are processed on quarterly basis. \\u00e2\\u0080\\u00a2 Appropriately plan and execute each skill of operations in accordance with the department's policies and procedures. \\u00e2\\u0080\\u00a2 Manage relationships with business team, software development team and other services to achieve project objectives. Different software Worked till now: - a. CTL prime - Axis Bank Credit Cards b. Insight - For POS Machine technical operations for Amex (MID & TID Generation- ATOS (Venture Infotek) c. Ticket Management System - TATA Communications Private Services Ltd (ATM - NOC Operations) d. Branch Portal (Yalamanchili Software Exports Ltd) - Prepaid Cards (SBI Bank & Zaggle Prepaid Oceans Services Ltd) Zaggle Prepaid Ocean Services Pvt Ltd Oct, 2017 to Till Date Designation: Manager - Operations (Payment Industry - Prepaid Cards - INR) Education Details \\r\\n  Commerce Mumbai, Maharashtra Mumbai University\\r\\nOperations Manager \\r\\n\\r\\nService Manager - Operations (Payment Industry - Prepaid Cards - INR & FTC)\\r\\nSkill Details \\r\\nOPERATIONS- Exprience - 73 months\\r\\nSATISFACTION- Exprience - 48 months\\r\\nTRAINING- Exprience - 24 months\\r\\nNOC- Exprience - 23 months\\r\\nPOINT OF SALE- Exprience - 20 monthsCompany Details \\r\\ncompany - Zaggle Prepaid Ocean Services Pvt Ltd\\r\\ndescription - Card Operations\\r\\ncompany - Yalamanchili Software Exports Ltd\\r\\ndescription - 24*7 Operations Pvt Ltd) Dec 2015 to Feb 2017\\r\\n\\r\\nDesignation: Service Manager - Operations (Payment Industry - Prepaid Cards - INR & FTC)\\r\\n\\r\\nKey Contributions: \\u00e2\\u0080\\u00a2 A result-oriented business professional in planning, executing& managing processes, improving efficiency of operations, team building and detailing process information to determine effective result into operations.\\r\\n\\u00e2\\u0080\\u00a2 Ensuring PINs generation (SLA) is maintained and chargeback cases are raised in perfect timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Managing email customer services properly and ensuring the emails are replied properly. Also, ensuring transaction monitoring is properly managed 24/7.\\r\\n\\u00e2\\u0080\\u00a2 Assisting Bankers (SBI & Associated Banks) for their BCP plans by getting executed in the system with the help of DR-PR plans & vice versa or any other business requirements.\\r\\n\\u00e2\\u0080\\u00a2 Expertise in maintaining highest level of quality in operations; ensuring adherence to all the quality parameters and procedures as per the stringent norms.\\r\\n\\u00e2\\u0080\\u00a2 Lead, manage and supervise the execution of external audit engagements and responsible for presenting the findings & developing a quality reports to the senior Management and Clients.\\r\\n\\u00e2\\u0080\\u00a2 Coach/mentor (20) team members to perform at a higher level by giving opportunities, providing timely continuous feedback and working with staff to improve their communication, time management, decision making, organization, and analytical skills.\\r\\n\\u00e2\\u0080\\u00a2 Providing the solutions and services to the client in their own premises with aforesaid count of team members.\\r\\n\\u00e2\\u0080\\u00a2 Also ensuring end to end process of PR & DR as per client requirements (PR- DR & DR -PR) by interacting with internal & external stakeholders.\\r\\n\\u00e2\\u0080\\u00a2 Determining process gaps and designing & conducting training programs to enhance operational efficiency and retain talent by providing optimum opportunities for personal and professional growth.\\r\\ncompany - Credit Cards\\r\\ndescription - Ensured highest standard of customer satisfaction and quality service; developing new policies and procedures to improve based on customer feedback and resolving customer queries via correspondence, inbound calls & email channels with the strength of (12-16) Team members.\\r\\ncompany - AGS Transact Technologies Limited\\r\\ndescription - Key Contributions: Lead - SPOC to Banks\\r\\ncompany - TATA Communications Payment Solutions Ltd\\r\\ndescription - To make ATMs operational within TAT by analyzing the issue is technical or non-technical and also by interacting with internal & external stakeholders.\\r\\ncompany - Vertex Customer Solutions India Private Ltd\\r\\ndescription - Key Contributions: \\u00e2\\u0080\\u00a2 Build positive working relationship with all team members and clients by keeping Management informed   of KYC document collection & con-current audit progress, responding timely to Management inquiries, understanding the business and conducting self professionally.\\r\\ncompany - Financial Inclusion Network & Operations Limited\\r\\ndescription - Key Contributions: POS-Operations \\u00e2\\u0080\\u00a2 Cascading the adherence of process is strictly followed by team members & training them to reduce the downtime.\\r\\n\\u00e2\\u0080\\u00a2 Managing Stock of EDC Terminals \\u00e2\\u0080\\u00a2 Managing Deployments of terminals through Multiple teams \\u00e2\\u0080\\u00a2 Would have worked with multiple terminal make & model \\u00e2\\u0080\\u00a2 Managing Inward, Outward & QC of applications installed in the POS machines.\\r\\ncompany - Venture Infotek Private Ltd\\r\\ndescription - Key Contributions: POS-Operations\\r\\ncompany - Axis Bank Ltd - Customer Services\\r\\ndescription - Aug 2006 to Oct 2009 (Ma-Foi&I- smart)\\r\\n\\r\\nDesignation: Team Leader/Executive - Emails, Phone Banking & Correspondence Unit (Snail Mails)\",\n          \"Skill Set: Hadoop, Map Reduce, HDFS, Hive, Sqoop, java. Duration: 2016 to 2017. Role: Hadoop Developer Rplus offers an quick, simple and powerful cloud based Solution, Demand Sense to accurately predict demand for your product in all your markets which Combines Enterprise and External Data to predict demand more accurately through Uses Social Conversation and Sentiments to derive demand and Identifies significant drivers of sale out of hordes of factors that Selects the best suited model out of multiple forecasting models for each product. Responsibilities: \\u00e2\\u0080\\u00a2 Involved in deploying the product for customers, gathering requirements and algorithm optimization at backend of the product. \\u00e2\\u0080\\u00a2 Load and transform Large Datasets of structured semi structured. \\u00e2\\u0080\\u00a2 Responsible to manage data coming from different sources and application \\u00e2\\u0080\\u00a2 Supported Map Reduce Programs those are running on the cluster \\u00e2\\u0080\\u00a2 Involved in creating Hive tables, loading with data and writing hive queries which will run internally in map reduce way.Education Details \\r\\n\\r\\nHadoop Developer \\r\\n\\r\\nHadoop Developer - Braindatawire\\r\\nSkill Details \\r\\nAPACHE HADOOP HDFS- Exprience - 49 months\\r\\nAPACHE HADOOP SQOOP- Exprience - 49 months\\r\\nHadoop- Exprience - 49 months\\r\\nHADOOP- Exprience - 49 months\\r\\nHADOOP DISTRIBUTED FILE SYSTEM- Exprience - 49 monthsCompany Details \\r\\ncompany - Braindatawire\\r\\ndescription - Technical Skills:\\r\\n\\u00e2\\u0080\\u00a2   Programming: Core Java, Map Reduce, Scala\\r\\n\\u00e2\\u0080\\u00a2   Hadoop Tools: HDFS, Spark, Map Reduce, Sqoop, Hive, Hbase\\r\\n\\u00e2\\u0080\\u00a2   Database: MySQL, Oracle\\r\\n\\u00e2\\u0080\\u00a2   Scripting: Shell Scripting\\r\\n\\u00e2\\u0080\\u00a2   IDE: Eclipse\\r\\n\\u00e2\\u0080\\u00a2   Operating Systems: Linux (CentOS), Windows\\r\\n\\u00e2\\u0080\\u00a2   Source Control: Git (Github)\",\n          \"IT Skills: Area Exposure Modeling Tool: Bizagi, MS Visio Prototyping Tool: Indigo Studio. Documentation: MS Office (MS Word, MS Excel, MS Power Point) Testing Proficiency: Smoke, Sanity, Integration, Functional, Acceptance and UI Methodology implemented: Waterfall, Agile (Scrum) Database: SQL Testing Tool: HPQC Business Exposure Education Details \\r\\n Bachelor Of Computer Engineering Computer Engineering Mumbai, Maharashtra Thadomal Shahani Engineering college\\r\\n Diploma Computer Engineering Ulhasnagar, Maharashtra Institute of Technology\\r\\n Secondary School Certificate  Ulhasnagar, Maharashtra New English High School\\r\\nSenior Business Analyst - RPA \\r\\n\\r\\nSenior Business Analyst - RPA - Hexaware Technologies\\r\\nSkill Details \\r\\nDOCUMENTATION- Exprience - 47 months\\r\\nTESTING- Exprience - 29 months\\r\\nINTEGRATION- Exprience - 25 months\\r\\nINTEGRATOR- Exprience - 25 months\\r\\nPROTOTYPE- Exprience - 13 monthsCompany Details \\r\\ncompany - Hexaware Technologies\\r\\ndescription - Working as a RPA Business Analyst\\r\\ncompany - BBH- Brown Brothers Harriman & Co\\r\\ndescription - is a private bank that provides commercial banking, investment management, brokerage, and trust services to private companies and individuals. It also performs merger advisory, foreign exchange, custody services, commercial banking, and corporate financing services.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Performed Automation Assessment of various Processes and identified processes which can be candidates of RPA.\\r\\n\\u00e2\\u0080\\u00a2 Conducting Assessment that involves an initial Understanding of the Existing System, their technology, processes, Usage of the tools, Feasibility of tool with automation tool along with automation ROI analysis.\\r\\n\\u00e2\\u0080\\u00a2 Preparing the Automation Potential Sheet which describes the steps in the process, the volume and frequency of the transaction, the AHT taken by SME to perform the process and depending on the steps that could be automated, Automation potential and the manual efforts that will be saved are calculated.\\r\\nCalculating the complexity of the Process which is considered for automation and depending on all these factors Number of Bots and Number of Automation tool Licenses are determined.\\r\\n\\u00e2\\u0080\\u00a2 Implementing a Proof of Concept (POC) to Validate Feasibility by executing the selected critical use cases for conducting a POC which will helps to identify financial and operational benefits and provide recommendations regarding the actual need for complete automation.\\r\\n\\u00e2\\u0080\\u00a2 Gathering business requirements by conducting detailed interviews with business users, stakeholders, and Subject Matter Experts (SME's) \\u00e2\\u0080\\u00a2 Preparing Business Requirement Document and then converted Business requirements into Functional Requirements Specification.\\r\\n \\u00e2\\u0080\\u00a2 Constructing prototype early toward a design acceptable to the customer and feasible.\\r\\n\\u00e2\\u0080\\u00a2 Assisting in designing test plans, test scenarios and test cases for integration, regression, and user acceptance testing (UAT) to improve the overall quality of the Automation.\\r\\n\\u00e2\\u0080\\u00a2 Participating regularly in Walkthroughs and Review meetings with Project Manager, QA Engineers, and Development team.\\r\\n\\u00e2\\u0080\\u00a2 Regularly interacting with offshore and onshore development teams.\\r\\ncompany - FADV - First Advantage\\r\\ndescription - is a criminal background check company that delivers global solutions ranging from employment screenings to background checks.\\r\\nThe following are the processes which were covered:\\r\\nEmail Process, Research Process, Review Process.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Requirement Gathering through conducting Interviews & Brainstorming sessions with stakeholders \\u00e2\\u0080\\u00a2 To develop decision models and execute those rules as per the use case specifications.\\r\\n\\u00e2\\u0080\\u00a2 To Test/validate the decision models against document test data.\\r\\n\\u00e2\\u0080\\u00a2 To maintain and enhance the decision models for changes in regulations as per use case specifications.\\r\\n\\u00e2\\u0080\\u00a2 Responsible for performing the business research that will make a business growth.\\r\\n\\u00e2\\u0080\\u00a2 Developing a clear understanding of existing business functions and processes.\\r\\n\\u00e2\\u0080\\u00a2 Effectively communicate with the onsite clients for the queries, suggestions, and update.\\r\\n\\u00e2\\u0080\\u00a2 Giving suggestions to enhance the current processes.\\r\\n\\u00e2\\u0080\\u00a2 Identifying areas for process improvement.\\r\\n\\u00e2\\u0080\\u00a2 Flagging up potential problems at an early stage.\\r\\n\\u00e2\\u0080\\u00a2 Preparing PowerPoint presentations and documents for business meetings.\\r\\n\\u00e2\\u0080\\u00a2 Using any information gathered to write up detailed reports.\\r\\n\\u00e2\\u0080\\u00a2 Highlighting risks and issues that could impact project delivery.\\r\\n\\u00e2\\u0080\\u00a2 Able to work accurately.\\r\\n\\u00e2\\u0080\\u00a2 To develop and maintain documentation for internal team training and client end user operations.\\r\\n\\u00e2\\u0080\\u00a2 To work efficiently with team members and across teams.\\r\\n\\u00e2\\u0080\\u00a2 To mentor and train junior team members.\\r\\ncompany - Clinical Testing, Lab Work and Diagnostic Testing\\r\\ndescription - IQVIA provides services to its customers this includes: Clinical Testing, Lab Work and Diagnostic Testing under clinical trial. These customers need to pay to IQVIA and aging details and invoices are generated for the same.\\r\\nThe following are the processes which were covered:\\r\\n\\r\\nTracking Payments, Automated Real Time Metrics Reporting (Dashboard), Past Due Notifications, AR Statements, Credit/Rebill.\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Conducting meetings with clients and key stakeholders to gather requirements, analyze, finalize and have formal sign-offs from approvers Gather and perform analysis of the business requirements \\u00e2\\u0080\\u00a2 Translating the business requirements into the Business Requirement Document [BRD], Functional Requirement Document [FRD].\\r\\n\\u00e2\\u0080\\u00a2 Facilitating meetings with the appropriate subject matter experts in both business and technology teams \\u00e2\\u0080\\u00a2 Coordinating with business user community for the execution of user acceptance test as well as tracking issues \\u00e2\\u0080\\u00a2 Working, collaborating and coordinating with Offshore and Onsite team members to fulfill the BA responsibilities from project initiation to Post-Implementation \\u00e2\\u0080\\u00a2 Reviewing the test scripts with business users as well as technology team. Execute test scripts with expected results for the System Integration Test (SIT) and User Acceptance Test (UAT) \\u00e2\\u0080\\u00a2 Coordinating and conducting the Production Acceptance Testing (PAT) with the business users \\u00e2\\u0080\\u00a2 Creating flow diagrams, structure charts, and other types of system or process representations \\u00e2\\u0080\\u00a2 Managing changes to requirements and baseline through a change control process \\u00e2\\u0080\\u00a2 Utilizing standard methods, design and testing tools throughout project development life cycle \\u00e2\\u0080\\u00a2 Work closely with the operational functional teams, operations management, and personnel, and various technology teams to facilitate a shared understanding of requirements and priorities across all areas\\r\\ncompany - Eduavenir IT Solution\\r\\ndescription - Project: M.B.M.S\\r\\n\\r\\nM.B.M.S. - is an Inventory management application that allows user to manage inventory details of different warehouses, having different products located at various locations and help extract what goods have been procured, sold or returned by customers. It generates automated invoicesalong withcustomized reports. It also managescustomer complaint and resolution system implementation along with automated MIS on monthly basis.Sales and forecastingis also developed on MIS System and the streamlining of process of warehousing and dispatch along with online proof of delivery management system (POD documentation) is generated.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Participate in requirement gathering discussion with client to understand the flow of business processes \\u00e2\\u0080\\u00a2 Analyze the requirements and determine the core processes, develop Process Documentation and ensure to stay up-to-date in conjunction with on-going changes \\u00e2\\u0080\\u00a2 Participate in process flow analysis and preparing BRD, SRS.\\r\\n\\u00e2\\u0080\\u00a2 Coordinating with developers, designers & operations teams for various nuances of the project, communicate the stakeholder requirements from requirement /enhancement to implementation and finally deliver the same within estimated timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Support UAT by reviewing test cases, manage version control of documents, software builds.\\r\\n\\u00e2\\u0080\\u00a2 Coordinate with the stakeholders for UAT sign off and coordinate internally for production movement till Golive stage of the application.\\r\\n\\u00e2\\u0080\\u00a2 Provide demo and training to internal and end user using PowerPoint presentation.\\r\\n\\u00e2\\u0080\\u00a2 Resolving project functional &technical issues during UAT.\\r\\n\\u00e2\\u0080\\u00a2 Prioritizing the Production bugs and resolving the same within the estimated timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Preparing Project Status Report and Production Bugs Status to all the stakeholders.\\r\\n\\u00e2\\u0080\\u00a2 Promoting and Networking for online trading platform.\\r\\n\\u00e2\\u0080\\u00a2 Designing query sheet for obtaining and comparison of quotes from various vendors.\\r\\n\\u00e2\\u0080\\u00a2 Development of product codes / material codes for inventory management (Master Data Management)\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Type: Mobile and Device Testing.       Duration: January 2014 - August 2014\\r\\n\\r\\nFollet - An application which takes an electronic request from the user for the books he requires from a particular follet store. This detailed information about books that will include the name of the book, its price, the date of the transaction and the parties involved which will then be sent to follet stores. User then create request for one or more books for a given date. This request is then processed further and user gets a mail of the date when he will be provided with that book.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the needs and business requirements.\\r\\n\\u00e2\\u0080\\u00a2 Preparing BRD, SRS by eliciting all the requirements from the client and SMEs \\u00e2\\u0080\\u00a2 Understanding the dependency of the modules in the system \\u00e2\\u0080\\u00a2 Preparation of test plan for Unit level and Integration level.\\r\\n\\u00e2\\u0080\\u00a2 Preparation and execution of test cases.\\r\\n\\u00e2\\u0080\\u00a2 Defect tracking, Issue Resolution, Risk Monitoring, Status Tracking, Reporting and Follow-up.\\r\\n\\u00e2\\u0080\\u00a2 Preparation of Test Completion report.\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - \\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Humana is a health care insurance project of U.S. which deals with supplying various medicines to citizens as per the doctor's reference and patient's insurance policy. This application keeps track of all the medicines user has consumed in the past and generates a patient history. A citizen is given a drug only after the doctor's reference so the doctor's information is also linked with the patient's history.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the requirements and getting clarifications from client.\\r\\n\\u00e2\\u0080\\u00a2 Involved in writing test cases based on test scenarios and execute them.\\r\\n\\u00e2\\u0080\\u00a2 Ensuring Test Coverage using Requirement Traceability Matrix (RTM) \\u00e2\\u0080\\u00a2 Preparation of Test Completion report.\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Testing Trends WQR (World Quality Report) is an application which allows the users to take a survey on different methods and technologies used for testing. Users can choose to answer any type of questions under three different categories. Users have a facility to search, view and export the data to excel. Also, users get daily and weekly reports through email about the new trends in testing implemented around the globe. Testing Trends WQR app is available on Android and IOS platforms.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the requirements and getting clarifications from client.\\r\\n\\u00e2\\u0080\\u00a2 Writing test cases based on test scenarios and executed them.\\r\\n\\u00e2\\u0080\\u00a2 Performing different types of testing such as Functional, Integration, System, and UAT.\\r\\n\\u00e2\\u0080\\u00a2 Defect resolution and maintenance of the application.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def cleanResume(txt):\n",
        "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
        "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
        "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
        "    cleanText = re.sub('@\\S+', '  ', cleanText)\n",
        "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
        "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)\n",
        "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
        "    return cleanText"
      ],
      "metadata": {
        "id": "U54F084NbJYX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Resume']=df['Resume'].apply(lambda x:cleanResume(x))"
      ],
      "metadata": {
        "id": "ylQ-1DymbQWy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification problem\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()"
      ],
      "metadata": {
        "id": "NbhxoEmybV_y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.fit(df['Category'])\n",
        "df['Category']=le.transform(df['Category'])"
      ],
      "metadata": {
        "id": "EqrCArcNbYlh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Zoqo_CpEbbWO",
        "outputId": "819105b4-b647-469e-c261-bce41f9ea9e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Category                                             Resume\n",
              "0           6  Skills Programming Languages Python pandas num...\n",
              "1           6  Education Details May 2013 to May 2017 B E UIT...\n",
              "2           6  Areas of Interest Deep Learning Control System...\n",
              "3           6  Skills R Python SAP HANA Tableau SAP HANA SQL ...\n",
              "4           6  Education Details MCA YMCAUST Faridabad Haryan...\n",
              "..        ...                                                ...\n",
              "957        23  Computer Skills Proficient in MS office Word B...\n",
              "958        23   Willingness to a ept the challenges Positive ...\n",
              "959        23  PERSONAL SKILLS Quick learner Eagerness to lea...\n",
              "960        23  COMPUTER SKILLS SOFTWARE KNOWLEDGE MS Power Po...\n",
              "961        23  Skill Set OS Windows XP 7 8 8 1 10 Database MY...\n",
              "\n",
              "[962 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14a064e9-e0be-4a14-8643-a4b1198e085f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>Skills Programming Languages Python pandas num...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>Education Details May 2013 to May 2017 B E UIT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>Areas of Interest Deep Learning Control System...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Skills R Python SAP HANA Tableau SAP HANA SQL ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Education Details MCA YMCAUST Faridabad Haryan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>23</td>\n",
              "      <td>Computer Skills Proficient in MS office Word B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>23</td>\n",
              "      <td>Willingness to a ept the challenges Positive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>23</td>\n",
              "      <td>PERSONAL SKILLS Quick learner Eagerness to lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>23</td>\n",
              "      <td>COMPUTER SKILLS SOFTWARE KNOWLEDGE MS Power Po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>23</td>\n",
              "      <td>Skill Set OS Windows XP 7 8 8 1 10 Database MY...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>962 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a064e9-e0be-4a14-8643-a4b1198e085f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14a064e9-e0be-4a14-8643-a4b1198e085f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14a064e9-e0be-4a14-8643-a4b1198e085f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06acccd1-5cd8-41eb-90e8-c4b52ea3d58c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06acccd1-5cd8-41eb-90e8-c4b52ea3d58c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06acccd1-5cd8-41eb-90e8-c4b52ea3d58c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9e6603ae-4ce0-4184-b10e-8f97e98cce54\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9e6603ae-4ce0-4184-b10e-8f97e98cce54 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 962,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 24,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          5,\n          8,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resume\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"KEY COMPETENCIES Multi Operations Management People Management Customer Services Emails MIS Vendor Client Services Management Cross Functional Coordination Banking Financial Services Transaction Monitoring ATM Operations Prepaid Card Operations Pre Issuance Post Issuance POS Operations JOB PROFILE SKILLS An effective communicator with excellent relationship building interpersonal skills Strong analytical problem solving organizational abilities Extensive experience in managing operations with demonstrated leadership qualities organisational skills during the tenure Managing customer centric operations ensuring customer satisfaction by achieving service quality norms Analyzing of all operational problems customer complaints and take preventive and corrective actions to resolve the same Receive and respond to Key customer inquiries in an effective manner and provide relevant and timely information Deft in steering banking back end operations analyzing risks and managing delinquencies with dexterity across applying techniques for maximizing recoveries and minimizing credit losses Analyzed identified training needs of the team members and developing organizing and conducting training programs and manage bottom quartile team to improve their performance Preparing and maintaining daily MIS reports to evaluate the performance and efficiency of the process relate to various verticals Measuring the performance of the processes in terms of efficiency and effectiveness matrix and ensuring adherence to SLA Major Activities Define processes for Field Services were monitored and necessary checks were executed and controlled Also measured Vendor SLA by analyzing the TAT of vendors the Client SLA provided to us As per company procedures handling ensuring vendor s payment issues to be sorted out payments are processed on quarterly basis Appropriately plan and execute each skill of operations in a ordance with the department s policies and procedures Manage relationships with business team software development team and other services to achieve project objectives Different software Worked till now a CTL prime Axis Bank Credit Cards b Insight For POS Machine technical operations for Amex MID TID Generation ATOS Venture Infotek c Ticket Management System TATA Communications Private Services Ltd ATM NOC Operations d Branch Portal Yalamanchili Software Exports Ltd Prepaid Cards SBI Bank Zaggle Prepaid Oceans Services Ltd Zaggle Prepaid Ocean Services Pvt Ltd Oct 2017 to Till Date Designation Manager Operations Payment Industry Prepaid Cards INR Education Details Commerce Mumbai Maharashtra Mumbai University Operations Manager Service Manager Operations Payment Industry Prepaid Cards INR FTC Skill Details OPERATIONS Exprience 73 months SATISFACTION Exprience 48 months TRAINING Exprience 24 months NOC Exprience 23 months POINT OF SALE Exprience 20 monthsCompany Details company Zaggle Prepaid Ocean Services Pvt Ltd description Card Operations company Yalamanchili Software Exports Ltd description 24 7 Operations Pvt Ltd Dec 2015 to Feb 2017 Designation Service Manager Operations Payment Industry Prepaid Cards INR FTC Key Contributions A result oriented business professional in planning executing managing processes improving efficiency of operations team building and detailing process information to determine effective result into operations Ensuring PINs generation SLA is maintained and chargeback cases are raised in perfect timeframe Managing email customer services properly and ensuring the emails are replied properly Also ensuring transaction monitoring is properly managed 24 7 Assisting Bankers SBI Associated Banks for their BCP plans by getting executed in the system with the help of DR PR plans vice versa or any other business requirements Expertise in maintaining highest level of quality in operations ensuring adherence to all the quality parameters and procedures as per the stringent norms Lead manage and supervise the execution of external audit engagements and responsible for presenting the findings developing a quality reports to the senior Management and Clients Coach mentor 20 team members to perform at a higher level by giving opportunities providing timely continuous feedback and working with staff to improve their communication time management decision making organization and analytical skills Providing the solutions and services to the client in their own premises with aforesaid count of team members Also ensuring end to end process of PR DR as per client requirements PR DR DR PR by interacting with internal external stakeholders Determining process gaps and designing conducting training programs to enhance operational efficiency and retain talent by providing optimum opportunities for personal and professional growth company Credit Cards description Ensured highest standard of customer satisfaction and quality service developing new policies and procedures to improve based on customer feedback and resolving customer queries via correspondence inbound calls email channels with the strength of 12 16 Team members company AGS Transact Technologies Limited description Key Contributions Lead SPOC to Banks company TATA Communications Payment Solutions Ltd description To make ATMs operational within TAT by analyzing the issue is technical or non technical and also by interacting with internal external stakeholders company Vertex Customer Solutions India Private Ltd description Key Contributions Build positive working relationship with all team members and clients by keeping Management informed of KYC document collection con current audit progress responding timely to Management inquiries understanding the business and conducting self professionally company Financial Inclusion Network Operations Limited description Key Contributions POS Operations Cascading the adherence of process is strictly followed by team members training them to reduce the downtime Managing Stock of EDC Terminals Managing Deployments of terminals through Multiple teams Would have worked with multiple terminal make model Managing Inward Outward QC of applications installed in the POS machines company Venture Infotek Private Ltd description Key Contributions POS Operations company Axis Bank Ltd Customer Services description Aug 2006 to Oct 2009 Ma Foi I smart Designation Team Leader Executive Emails Phone Banking Correspondence Unit Snail Mails \",\n          \"Skill Set Hadoop Map Reduce HDFS Hive Sqoop java Duration 2016 to 2017 Role Hadoop Developer Rplus offers an quick simple and powerful cloud based Solution Demand Sense to a urately predict demand for your product in all your markets which Combines Enterprise and External Data to predict demand more a urately through Uses Social Conversation and Sentiments to derive demand and Identifies significant drivers of sale out of hordes of factors that Selects the best suited model out of multiple forecasting models for each product Responsibilities Involved in deploying the product for customers gathering requirements and algorithm optimization at backend of the product Load and transform Large Datasets of structured semi structured Responsible to manage data coming from different sources and application Supported Map Reduce Programs those are running on the cluster Involved in creating Hive tables loading with data and writing hive queries which will run internally in map reduce way Education Details Hadoop Developer Hadoop Developer Braindatawire Skill Details APACHE HADOOP HDFS Exprience 49 months APACHE HADOOP SQOOP Exprience 49 months Hadoop Exprience 49 months HADOOP Exprience 49 months HADOOP DISTRIBUTED FILE SYSTEM Exprience 49 monthsCompany Details company Braindatawire description Technical Skills Programming Core Java Map Reduce Scala Hadoop Tools HDFS Spark Map Reduce Sqoop Hive Hbase Database MySQL Oracle Scripting Shell Scripting IDE Eclipse Operating Systems Linux CentOS Windows Source Control Git Github \",\n          \"IT Skills Area Exposure Modeling Tool Bizagi MS Visio Prototyping Tool Indigo Studio Documentation MS Office MS Word MS Excel MS Power Point Testing Proficiency Smoke Sanity Integration Functional A eptance and UI Methodology implemented Waterfall Agile Scrum Database SQL Testing Tool HPQC Business Exposure Education Details Bachelor Of Computer Engineering Computer Engineering Mumbai Maharashtra Thadomal Shahani Engineering college Diploma Computer Engineering Ulhasnagar Maharashtra Institute of Technology Secondary School Certificate Ulhasnagar Maharashtra New English High School Senior Business Analyst RPA Senior Business Analyst RPA Hexaware Technologies Skill Details DOCUMENTATION Exprience 47 months TESTING Exprience 29 months INTEGRATION Exprience 25 months INTEGRATOR Exprience 25 months PROTOTYPE Exprience 13 monthsCompany Details company Hexaware Technologies description Working as a RPA Business Analyst company BBH Brown Brothers Harriman Co description is a private bank that provides commercial banking investment management brokerage and trust services to private companies and individuals It also performs merger advisory foreign exchange custody services commercial banking and corporate financing services Responsibilities Performed Automation Assessment of various Processes and identified processes which can be candidates of RPA Conducting Assessment that involves an initial Understanding of the Existing System their technology processes Usage of the tools Feasibility of tool with automation tool along with automation ROI analysis Preparing the Automation Potential Sheet which describes the steps in the process the volume and frequency of the transaction the AHT taken by SME to perform the process and depending on the steps that could be automated Automation potential and the manual efforts that will be saved are calculated Calculating the complexity of the Process which is considered for automation and depending on all these factors Number of Bots and Number of Automation tool Licenses are determined Implementing a Proof of Concept POC to Validate Feasibility by executing the selected critical use cases for conducting a POC which will helps to identify financial and operational benefits and provide recommendations regarding the actual need for complete automation Gathering business requirements by conducting detailed interviews with business users stakeholders and Subject Matter Experts SME s Preparing Business Requirement Document and then converted Business requirements into Functional Requirements Specification Constructing prototype early toward a design a eptable to the customer and feasible Assisting in designing test plans test scenarios and test cases for integration regression and user a eptance testing UAT to improve the overall quality of the Automation Participating regularly in Walkthroughs and Review meetings with Project Manager QA Engineers and Development team Regularly interacting with offshore and onshore development teams company FADV First Advantage description is a criminal background check company that delivers global solutions ranging from employment screenings to background checks The following are the processes which were covered Email Process Research Process Review Process Responsibilities Requirement Gathering through conducting Interviews Brainstorming sessions with stakeholders To develop decision models and execute those rules as per the use case specifications To Test validate the decision models against document test data To maintain and enhance the decision models for changes in regulations as per use case specifications Responsible for performing the business research that will make a business growth Developing a clear understanding of existing business functions and processes Effectively communicate with the onsite clients for the queries suggestions and update Giving suggestions to enhance the current processes Identifying areas for process improvement Flagging up potential problems at an early stage Preparing PowerPoint presentations and documents for business meetings Using any information gathered to write up detailed reports Highlighting risks and issues that could impact project delivery Able to work a urately To develop and maintain documentation for internal team training and client end user operations To work efficiently with team members and across teams To mentor and train junior team members company Clinical Testing Lab Work and Diagnostic Testing description IQVIA provides services to its customers this includes Clinical Testing Lab Work and Diagnostic Testing under clinical trial These customers need to pay to IQVIA and aging details and invoices are generated for the same The following are the processes which were covered Tracking Payments Automated Real Time Metrics Reporting Dashboard Past Due Notifications AR Statements Credit Rebill Responsibilities Conducting meetings with clients and key stakeholders to gather requirements analyze finalize and have formal sign offs from approvers Gather and perform analysis of the business requirements Translating the business requirements into the Business Requirement Document BRD Functional Requirement Document FRD Facilitating meetings with the appropriate subject matter experts in both business and technology teams Coordinating with business user community for the execution of user a eptance test as well as tracking issues Working collaborating and coordinating with Offshore and Onsite team members to fulfill the BA responsibilities from project initiation to Post Implementation Reviewing the test scripts with business users as well as technology team Execute test scripts with expected results for the System Integration Test SIT and User A eptance Test UAT Coordinating and conducting the Production A eptance Testing PAT with the business users Creating flow diagrams structure charts and other types of system or process representations Managing changes to requirements and baseline through a change control process Utilizing standard methods design and testing tools throughout project development life cycle Work closely with the operational functional teams operations management and personnel and various technology teams to facilitate a shared understanding of requirements and priorities across all areas company Eduavenir IT Solution description Project M B M S M B M S is an Inventory management application that allows user to manage inventory details of different warehouses having different products located at various locations and help extract what goods have been procured sold or returned by customers It generates automated invoicesalong withcustomized reports It also managescustomer complaint and resolution system implementation along with automated MIS on monthly basis Sales and forecastingis also developed on MIS System and the streamlining of process of warehousing and dispatch along with online proof of delivery management system POD documentation is generated Responsibilities Participate in requirement gathering discussion with client to understand the flow of business processes Analyze the requirements and determine the core processes develop Process Documentation and ensure to stay up to date in conjunction with on going changes Participate in process flow analysis and preparing BRD SRS Coordinating with developers designers operations teams for various nuances of the project communicate the stakeholder requirements from requirement enhancement to implementation and finally deliver the same within estimated timeframe Support UAT by reviewing test cases manage version control of documents software builds Coordinate with the stakeholders for UAT sign off and coordinate internally for production movement till Golive stage of the application Provide demo and training to internal and end user using PowerPoint presentation Resolving project functional technical issues during UAT Prioritizing the Production bugs and resolving the same within the estimated timeframe Preparing Project Status Report and Production Bugs Status to all the stakeholders Promoting and Networking for online trading platform Designing query sheet for obtaining and comparison of quotes from various vendors Development of product codes material codes for inventory management Master Data Management company CAPGEMINI Head Office description Type Mobile and Device Testing Duration January 2014 August 2014 Follet An application which takes an electronic request from the user for the books he requires from a particular follet store This detailed information about books that will include the name of the book its price the date of the transaction and the parties involved which will then be sent to follet stores User then create request for one or more books for a given date This request is then processed further and user gets a mail of the date when he will be provided with that book Responsibilities Understanding the needs and business requirements Preparing BRD SRS by eliciting all the requirements from the client and SMEs Understanding the dependency of the modules in the system Preparation of test plan for Unit level and Integration level Preparation and execution of test cases Defect tracking Issue Resolution Risk Monitoring Status Tracking Reporting and Follow up Preparation of Test Completion report company CAPGEMINI Head Office description company CAPGEMINI Head Office description Humana is a health care insurance project of U S which deals with supplying various medicines to citizens as per the doctor s reference and patient s insurance policy This application keeps track of all the medicines user has consumed in the past and generates a patient history A citizen is given a drug only after the doctor s reference so the doctor s information is also linked with the patient s history Responsibilities Understanding the requirements and getting clarifications from client Involved in writing test cases based on test scenarios and execute them Ensuring Test Coverage using Requirement Traceability Matrix M Preparation of Test Completion report company CAPGEMINI Head Office description Testing Trends WQR World Quality Report is an application which allows the users to take a survey on different methods and technologies used for testing Users can choose to answer any type of questions under three different categories Users have a facility to search view and export the data to excel Also users get daily and weekly reports through email about the new trends in testing implemented around the globe Testing Trends WQR app is available on Android and IOS platforms Responsibilities Understanding the requirements and getting clarifications from client Writing test cases based on test scenarios and executed them Performing different types of testing such as Functional Integration System and UAT Defect resolution and maintenance of the application \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer(stop_words='english')\n",
        "tfidf.fit(df['Resume'])\n",
        "requiredText=tfidf.transform(df['Resume'])"
      ],
      "metadata": {
        "id": "47C9oTPRbb6P"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-635MAQXbhMo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(requiredText,df['Category'],test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "_ccFrH9nbhzk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf=OneVsRestClassifier(KNeighborsClassifier())\n",
        "clf.fit(X_train,y_train)\n",
        "ypred=clf.predict(X_test)\n",
        "print(accuracy_score(y_test,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UBwO8p-bjsy",
        "outputId": "9bdd46ad-fd75-4998-abeb-9cac97c8b74a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9844559585492227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
        "pickle.dump(clf,open('clf.pkl','wb'))"
      ],
      "metadata": {
        "id": "gucX27bOblae"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myresume=\"\"\"Vrishank J Vasist\n",
        "E-mail:\n",
        "vrishank.cs21@bmsce.ac.in\n",
        " Phone: 8870066818\n",
        "Objectives:\n",
        "➢ To strive for excellence, to work in an environment that will enhance my knowledge and career, work hard with full\n",
        "dedication and to achieve personal and organizational goals.\n",
        "Education\n",
        "➢ 2021 – 2025:  Computer Science at BMS College of Engineering, Bull Temple Road, Bangalore, Karnataka.\n",
        "➢ 2019 - 2021: 91%. Pre-University College - Sri Chaitanya PU College, Koramangala, Bangalore, Karnataka.\n",
        "➢ 2018 - 2019: S.S.L.C at Sri Chaitanya Techno School, Electronic City, Bangalore, Karnataka. Passed out with 92.8%.\n",
        "Skills and Certifications\n",
        "➢ Technical Skills: Python, Django, SQL, JavaScript, Java, C\n",
        "➢ Tools and Technologies: Git, VS Code, Jupyter Notebook, Google Colab, Bootstrap.\n",
        "➢ Certifications: Azure AI Fundamentals, Azure Fundamentals, Udemy Python Course, Udemy\n",
        "JavaScript Course.\n",
        "Work Experience:\n",
        "➢ Technical Internship at BMS College of Engineering. Researched Image Classification and Recognition\n",
        "using Neural Networks and ML under Assistant Professor Sneha S Bagalkot.\n",
        "➢ 6 Month Virtual Internship from Samsung Prism working on Image Enhancement using Neural\n",
        "Networks and ML.\n",
        "Projects:\n",
        "➢ Discussion Forum: Fully Functional Discussion Website made using Django and stylized using\n",
        "Bootstrap.\n",
        "➢ Image Classification Application: Machine Learning CNN Model created using TensorFlow.\n",
        "Classifies objects into three categories.\n",
        "➢ Fitness Application: Application made completely in Java consisting of various features such as\n",
        "Water Tracking, Calorie Counting and many calculators.\n",
        "Personal Details\n",
        "➢ Name: Vrishank J Vasist\n",
        "➢ Date of Birth: 8th April 2003\n",
        "➢ Nationality: Indian\n",
        "➢ Languages: English, Kannada, Hindi, Tamil\n",
        "Declaration\n",
        "I hereby declare that the details furnished above are true and correct to the best of my knowledge.\n",
        "Date: 6th November 2023\n",
        "Place: Bangalore, Karnataka \"\"\""
      ],
      "metadata": {
        "id": "u12hUfeWbqEE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "#load the trained classifier\n",
        "clf=pickle.load(open('clf.pkl','rb'))\n",
        "\n",
        "#clean the input resume\n",
        "cleanedResume=cleanResume(myresume)\n",
        "\n",
        "#transform the cleaned resume using the trained tfidfvectorization\n",
        "inputFeatures=tfidf.transform([cleanedResume])\n",
        "\n",
        "#make the prediction using the loaded classifier\n",
        "predictionId=clf.predict(inputFeatures)[0]\n",
        "\n",
        "#map category ID to category name\n",
        "categoryMapping = {\n",
        "    15: \"Java Developer\",\n",
        "    23: \"Testing\",\n",
        "    8: \"DevOps Engineer\",\n",
        "    20: \"Python Developer\",\n",
        "    24: \"Web Designing\",\n",
        "    12: \"HR\",\n",
        "    13: \"Hadoop\",\n",
        "    3: \"Blockchain\",\n",
        "    10: \"ETL Developer\",\n",
        "    18: \"Operations Manager\",\n",
        "    6: \"Data Science\",\n",
        "    22: \"Sales\",\n",
        "    16: \"Mechanical Engineer\",\n",
        "    1: \"Arts\",\n",
        "    7: \"Database\",\n",
        "    11: \"Electrical Engineering\",\n",
        "    14: \"Health and fitness\",\n",
        "    19: \"PMO\",\n",
        "    4: \"Business Analyst\",\n",
        "    9: \"DotNet Developer\",\n",
        "    2: \"Automation Testing\",\n",
        "    17: \"Network Security Engineer\",\n",
        "    21: \"SAP Developer\",\n",
        "    5: \"Civil Engineer\",\n",
        "    0: \"Advocate\",\n",
        "}\n",
        "categoryName = categoryMapping.get(predictionId, \"Unknown\")\n",
        "\n",
        "print(\"Predicted Category:\", categoryName)\n",
        "print(predictionId)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ2XEr_Pbqiz",
        "outputId": "37955bbd-92ac-4ac8-f154-08120f1bc5c9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: Data Science\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc =nlp('''Harika N\n",
        "B.E. in Computer Science Engineering harikatanguturi13@gmail.com\n",
        "B.M.S College of Engineering, Bangalore 9206547808\n",
        "CAREER OBJECTIVE:\n",
        "An energetic, ambitious, and highly motivated individual seeking a challenging profession in\n",
        "computer science that will allow me to convey my theoretical and practical skills while also allowing\n",
        "me to advance in my technological interests.\n",
        "EDUCATIONAL QUALIFICATIONS:\n",
        "B.M.S College of Engineering 2021-2025\n",
        "B.E. in CSE, CGPA: 9.48 /10 Bangalore, India\n",
        "MS Ramaiah Composite PU College 2019-2021\n",
        "PUC (Class XII), Aggregate: 99.1 Bangalore, India\n",
        "SJR Primary and High School 2018-2019\n",
        "SSLC (Class X), Aggregate: 97.7 Bangalore, India\n",
        "TECHNICAL SKILLS:\n",
        "Languages: C, JavaScript, Java, HTML, CSS, SQL\n",
        "Frameworks: Node.js, express.js\n",
        "Database: MySQL, MongoDB, Firebase\n",
        "Libraries: Numpy, Pandas, Matplotlib\n",
        "Tools/Technologies: VS Code, Google Collab, GitHub, Docker Hub, Figma\n",
        "PROJECTS:\n",
        "Web Development Project\n",
        "It is a Library Management System website constructed to handle the movement of books and\n",
        "maintain records of library users using HTML, CSS, and JS in the frontend to connect MySQL and\n",
        "hosting on GitHub, as well as Docker Hub and built CI/CD pipelining.\n",
        "Mobile Application Project\n",
        "It is Inventory Management App that enables to visually track items and any of their details including\n",
        "quantity, price, condition, notes in a more intuitive way for a team to track the inventory across\n",
        "multiple locations. It is built using figma , flutter and firebase.\n",
        "R&D Intern\n",
        "Studied papers on various CAPTCHA mechanisms and a survey research paper was written which\n",
        "consisted of Skin detection sensor-based assistance for CAPTCHA which can overcome the\n",
        "limitations of traditional CAPTCHA using Internet of Things.\n",
        "DECLARATION:\n",
        "I hereby declare that information given is true, complete and correct to the best of my knowledge and\n",
        "belief.\n",
        "Place: Bengaluru (Harika N)''')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"--------->\" , ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EurJCPTpSWVE",
        "outputId": "f57633bb-f7f5-4456-c7a9-d3b45894b95c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harika N ---------> Name\n",
            "B.E. in Computer Science Engineering ---------> Degree\n",
            "B.M.S College of Engineering ---------> College Name\n",
            "B.M.S College of Engineering ---------> College Name\n",
            "2021 ---------> Graduation Year\n",
            "2025 ---------> Graduation Year\n",
            "B.E. in CSE ---------> Degree\n",
            "MS Ramaiah Composite PU College ---------> College Name\n",
            "2019 ---------> Graduation Year\n",
            "2021 ---------> Graduation Year\n",
            "SJR Primary and High School 2018-2019\n",
            "SSLC (Class X), Aggregate: 97.7 Bangalore, India ---------> College Name\n",
            "Languages: C, JavaScript, Java, HTML, CSS, SQL\n",
            "Frameworks: Node.js, express.js\n",
            "Database: MySQL, MongoDB, Firebase\n",
            "Libraries: Numpy, Pandas, Matplotlib\n",
            "Tools/Technologies: VS Code, Google Collab, GitHub, Docker Hub, Figma\n",
            "PROJECTS:\n",
            "Web Development Project\n",
            "It is a Library Management System website constructed to handle the movement of books and\n",
            "maintain records of library users using HTML, CSS, and JS in the frontend to connect MySQL and\n",
            "hosting on GitHub, as well as Docker Hub and built CI/CD pipelining.\n",
            "Mobile Application Project\n",
            "It is Inventory Management App that enables to visually track items and any of their details including\n",
            "quantity, price, condition, notes in a more intuitive way for a team to track the inventory across\n",
            "multiple locations. It is built using figma , flutter and firebase.\n",
            "R&D Intern\n",
            "Studied papers on various CAPTCHA mechanisms and a survey research paper was written which\n",
            "consisted of Skin detection sensor-based assistance for CAPTCHA which can overcome the\n",
            "limitations of traditional CAPTCHA using Internet of Things. ---------> Skills\n"
          ]
        }
      ]
    }
  ]
}